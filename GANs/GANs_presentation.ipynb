{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcaba94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today\n",
    "\n",
    "- Supervised vs Unsupervised Learning\n",
    "- Discriminative vs Genrative modelling \n",
    "- Generative Adversarial Networks (GANs)\n",
    "- Applications of GANs\n",
    "- Viewpoints and debates\n",
    "- Discriminator\n",
    "- Generator\n",
    "- Loss Function\n",
    "- Optimization\n",
    "- KL divergence and JSD\n",
    "- Types of GANs\n",
    "- Vector arthematics\n",
    "- Challenges\n",
    "- References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e60b59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What can AI do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6977257",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can AI think on it's own?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbdaaa2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can AI dream?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20064e86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning vs Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e053c5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Supervised\n",
    "main goal is to map x -> y\n",
    "where (x,y) are data and its labels\n",
    "#### Some Examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c522f9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### classification\n",
    "<img src = \"https://developers.google.com/static/machine-learning/guides/text-classification/images/TextClassificationExample.png\" style = \"width: 700px; height : 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ff3bb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Object detection\n",
    "<img src = \"https://1.bp.blogspot.com/-HKhrGghm3Z4/Xwd6oWNmCnI/AAAAAAAADRQ/Hff-ZgjSDvo7op7aUtdN--WSuMohSMn-gCLcBGAsYHQ/s1600/tensorflow2objectdetection.png\" style = \"width : 700px; height : 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3de8e3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Image Captioning\n",
    "<img src = \"https://mobidev.biz/wp-content/uploads/2021/07/deep-learning-image-captioning-example-3.jpg\" style = \"width : 700px; height : 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa9120",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Unsupervised Learning\n",
    "We just have data, No labels. Because of which we have to find the underlying patterns of the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b5648",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Clustering\n",
    "\n",
    "<p align=\"center\">\n",
    "        <img src=\"https://developers.google.com/static/machine-learning/clustering/images/ClusterUnlabeled.png\">\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cfebb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Dimensionality Reduction\n",
    "\n",
    "<p align=\"center\">\n",
    "        <img src=\"https://d3i71xaburhd42.cloudfront.net/8dc7a7af1685d6667d24f013ecc5fceeb2bcc689/7-Figure2-1.png\">\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b08ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Unsupervised Learning** is sill an active area of research, a lot of open problems.\n",
    "If you can manage to solve how to detect the underlying patterns of the data, you essentially solve the understanding of the visual world(the holy grail). \n",
    "Although we do not have many methods in this, we still prefer unsupervised whenever we can because the data is very cheap you do not need any labels which make room for more data. Also, Raw data is much cheaper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d9155",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discriminative VS Generative Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6da8eb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Discriminative Modelling** is where you train a model to discriminate like a mail is spam or not OR a image is fake or not.\n",
    " - speaking in terms of conditional probability $P(Y|{X=x}) = {P(X|Y).P(Y)} / {P(X)}$\n",
    " - where X = input features, x = particular input and Y = desired output we want to train our model on. \n",
    " - $P(X|Y).P(Y)$ is the likelihood and $P(X|Y)$ is the posterior\n",
    " - in context of Naive Bayes, the model learns the posterior from directly mapping the input feartures X to labels Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e4ba6c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Discriminative Models we have used or heard off\n",
    "   - Linear Regression\n",
    "   - Logistic Regression\n",
    "   - Random Forrest\n",
    "   - Support Vector Machines(SVMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5cfa9",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Density Estimation** is the probalility density estimation that describe the data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a65e879",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Generative Models** are models that generate new samples that belong to the same training data distribution that they were trained on i.e they generate sample based on the density function of the training data distribution.\n",
    "Based on the density function, the generative models are further divided into two groups\n",
    " - Implicit Density Estimation\n",
    "     - Tractable Density Estimation\n",
    "     - Apporximate Density Estimation\n",
    "         - VAEs and Markov Chains\n",
    " - Explicit Density Estimation\n",
    "     - Direct Density Estimation\n",
    "         - GANs\n",
    "     - Markov Chains\n",
    "         - GSNs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875bc48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"taxonamy.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ad603",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In contrast to what we saw with discriminative models, the generative models try to learn the joint distribution $P(Y,X)$ of the labels and the input data. \n",
    "- Joint Probability can be given by $P(X,Y) = P(X|Y)P(y)$ and this can be re-written as\n",
    "\n",
    "$$\\begin{split}\\begin{aligned}\n",
    "             P(Y|X) = P(X,Y)/P(X)\n",
    "             \\end{aligned}\\end{split}$$\n",
    "             \n",
    "\n",
    "- the goal here is to model the joint probabilities of X and Y using P(X,Y). Using the results we compute the posterior, P(Y|X) and learn the targeted model. \n",
    "- This distribution can also be used to create sample new instances of data either by jointly sampling new tuples (x,y) or sampling new data inputs using a targeted label, Y, with the following label P(X|Y=y) = P(X, Y)/P(Y)\n",
    "$P(X|Y=y) = P(X,Y)/P(Y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931005cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generative Models that we have used or heard off\n",
    "- Naive Bayes classifiers\n",
    "- Gaussian Mixture model\n",
    "- Hidden Markov Models\n",
    "- GANs\n",
    "- VAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d86e65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why Generative Models?\n",
    "- We've only seen discriminative models\n",
    "    - which predicts Y given Input X\n",
    "    - estimates P(Y|X)\n",
    "- Discriminative models several key limitations\n",
    "    - cannot model P(X), i.e the probalility od seeing a certain image. \n",
    "    - Thus, they can't sample from P(X) i.e cannot generate new samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac971ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How did GANs come to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5a52f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generative Adversarial Networks (GANs)\n",
    "Problem : Want to create samples from complex, high dimensional training distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d418cda",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Solution: you sample from a simple distribution like random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0610cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Important terms:\n",
    "- Generator\n",
    "- Discriminator\n",
    "- Two player min max game\n",
    "- Adversarial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba5d07",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Adversarial Training : Training in the worst possible inputs or in adversarial environments. \n",
    "It essentially means the players have conflicting motivations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f49cc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"GAN2.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cf455",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"https://editor.analyticsvidhya.com/uploads/28005GANS_working.jpg\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9a283",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Magic of GANs\n",
    "<p align=\"center\">\n",
    "        <img src=\"magicofgans.png\", >\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681cd6f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which image is real?\n",
    "<p align=\"center\">\n",
    "        <img src=\"magicofgans2.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2dd4c7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"magicofgans3.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e9ec4",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now, that we've seen that this generation process starts from a random noise, lets see the practical results how that might look. \n",
    "Also, You always make sure that the dimension of the noise input is less than the required output sample dimension. ($z_{dim} < D(G(z))_{dim}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0d1c6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some more examples\n",
    "<p align=\"center\">\n",
    "        <img src=\"facesgan.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d0d247",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"cifargan.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b221d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications of GAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8a51e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "   ## Image Resolution\n",
    "<p align=\"center\">\n",
    "        <img src=\"resolution.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfb3a2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inpainting\n",
    "<p align=\"center\">\n",
    "        <img src=\"inpainting.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e58d114",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Image to Image Translation\n",
    "<p align=\"center\">\n",
    "        <img src=\"imagetoimage.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddb2be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- snow to summer : https://www.youtube.com/watch?v=9VC0c3pndbI\n",
    "- celeb faces : https://www.youtube.com/watch?v=XOxxPcy5Gr4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fbad1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Medical Application\n",
    "<p align=\"center\">\n",
    "        <img src=\"medicalapplication.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82deb1e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Prediction and visualization of future of diseases\n",
    "<p align=\"center\">\n",
    "        <img src=\"diseaseprediction.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c480a55",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "GANs can also be used to predict by using gans to predict what the scans might look like in the near future based on our present scans which can help doctors to provide additional measures to prevent or cure in some cases or to take necessary measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fababe6d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **EDGE FILLING** is where you fill the edges of the given hand drawn image like a handbag or oranges something like that. \n",
    "- **IMAGE SYNTHESIS** is where you create images based on the text. For example: if given a bird on a wall you would get an image of bird on a wall\n",
    "- 2017 to 2019 are like the biggest years for GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59649d6",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Although GANs were introdued in 2014, 2017 is the year when GANs exploded. GAN Zoo(avinash hindupur) is like a repository that contains everything GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe806f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some Intersting links**\n",
    "-  The GAN ZOO (https://github.com/hindupuravinash/the-gan-zoo)\n",
    "-  https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942217ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Traditional Viewpoint** \n",
    "> \"When solving a problem of interset, do not solve a more general problem as an intermediate step. Try to get the answer that you really need than a more general one \" by Vapnik, 1995\n",
    "\n",
    "**Alternate Viewpoint**\n",
    "> \"The Generative model does indeed have a higher asymtotic error(as the number of training examples becomes large) than the discriminative model but the generator model may also approach its asymptotic error much faster than the discriminative model - possibly with a number of training examples that is only logarthematic, rather than linear, in the number of parameters\" by Ng and Jordan 2001. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da593b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discriminator\n",
    " - Incorporates supervised learning\n",
    " - Goal is to identify if the sample are real or fake\n",
    " - The discriminator is like a police that has to identify the fake currency\n",
    "  <p align=\"center\">\n",
    "        <img src=\"discriminator.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793465f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Now we build discriminator model\n",
    "def build_discriminator(img_size):\n",
    "    i = Input(shape=(img_size,))\n",
    "    x = Dense(512, activation=LeakyReLU(alpha=0.2))(i)\n",
    "    x = Dense(256, activation=LeakyReLU(alpha=0.2))(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(i, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb443f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generator\n",
    " - The generator generates images from random noice\n",
    " - gets feedback from the discriminator and tries to improve\n",
    " - Generator is like a smuggler who has to fool the police officer about his fake currency\n",
    "<p align=\"center\">\n",
    "        <img src=\"generator.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03abfbc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# First we start with the generator model \n",
    "latent_dim = 100\n",
    "def build_generator(latent_dim):\n",
    "    i = Input(shape=(latent_dim,))\n",
    "    x = Dense(256, activation=LeakyReLU(alpha=0.2))(i)\n",
    "    x = BatchNormalization(momentum=0.7)(x)\n",
    "    x = Dense(512, activation=LeakyReLU(alpha=0.2))(x)\n",
    "    x = BatchNormalization(momentum=0.7)(x)\n",
    "    x = Dense(1024, activation=LeakyReLU(alpha=0.2))(x)\n",
    "    x = BatchNormalization(momentum=0.7)(x)\n",
    "    x = Dense(D, activation='tanh')(x)  #because Image pixel is between -1 to 1.\n",
    "    model = Model(i, x)  #i is input x is output layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a7310",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"io.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270de18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**LEARNING PROCESS/ 2 PLAYER MIN MAX GAME**\n",
    "- This is also known as an adversarial setting where the two parties have conflicting motivations. \n",
    "- Generator tries to fool the discriminator whereas the discriminator tries to classify the image as real. \n",
    "- Both generator and discriminator try to outbest each other. \n",
    "- They help each other to improve. Generator helps the discriminator to classify correctly and the evolving discriminator pushs generator to produce more real looking images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a80349",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Adversarial Network** is training with the worst possible inputs and evolving in the adversarial nertwork. This is a important part of the Generative Adversarial Networks.\n",
    "- Unsupervised learning has been changed into supervised under adversarial framework. \n",
    "$$ Unsupervised ‚áí_{adversarial framework} Supervised $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c93dc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### COST FUNCTION\n",
    "<p align=\"center\">\n",
    "        <img src=\"costfunction.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0b447",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Draw and show how this works and the flipping. how terms are given.\n",
    "- Expection values is nothing but the average of the output values by the discriminator and generator over their respective   samples. Log is just to scales the numbers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a3ad3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $ ùîº_{x ‚àº p_{data}} log (D(X)) $ - discriminator output on the real data. similarly,\n",
    "- $ ùîº_{x ‚àº p_{z}} log 1- D(G(X))) $ - discriminative output on the generator's samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093ae4d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "According to the adversarial setting, \n",
    "- Discriminator tries to maximize the objective such that D(x) is close to 1(real) and D(G(z)) is close to 0(fake)\n",
    "- Generator tries to minimize objective such that D(G(z)) is close to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000821f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training of GANs\n",
    "As already said, we are going to training the model using minmax objective function. \n",
    "In this we are going to alternate between Gradient descent and gradient ascent.\n",
    "- **Gradient Ascent** on the Discriminator because it is maximization\n",
    "$$\n",
    "\\\\\n",
    "max_{d} [ùîº_{x ‚àº p_{data}} log D(X) + ùîº_{z ‚àº p_{z}}  log (1 - D(G(z)))] \n",
    "$$\n",
    "\n",
    "- **Gradient Descent** on the generator because it is a minization function.\n",
    "$$\n",
    "\\\\\n",
    "min_{g} [ ùîº_{z ‚àº p_{z}}  log (1 - D(G(z)))]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16598181",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"algorithm.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebd062",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Draw the graph and explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de18ffc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Instead of minimizing the likelihood of the discriminator being correct, we now maximize the likelihood of discriminator being wrong. \n",
    "- This also has the same objective but has much higher gradient signal from bad samples. \n",
    "- This method works much better in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c129d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "then the training equations become\n",
    "- **Gradient Ascent** on the Discriminator because it is maximization\n",
    "$$\n",
    "\\\\\n",
    "max_{d} [ùîº_{x ‚àº p_{data}} log D(X) + ùîº_{z ‚àº p_{z}}  log (1 - D(G(z)))] \n",
    "$$\n",
    "\n",
    "- **Gradient Ascent** on the generator but a different objective\n",
    "$$\n",
    "\\\\\n",
    "max_{g} [ ùîº_{z ‚àº p_{z}}  log (1 - D(G(z)))]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1d524",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"updatedalgo.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0af41b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"loss.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a1b38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"io1.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ba0f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"io2.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59bd2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimial Discriminator\n",
    "we know that\n",
    "\n",
    "\\begin{align}\n",
    "V(D, G) = ùîº_{x ‚àº p_{data}}  log D(x)  +  ùîº_{z ‚àº p_{(z)}} log [1 -D(G(z))]\n",
    "\\end{align}\n",
    "If we expand this to an integral form then we get, \n",
    "\\begin{align}\n",
    "‚à´_x p_{data} (x). log(D(x)) + ‚à´_z P_z (z) log (1-D(G(z)))\n",
    "\\end{align}\n",
    "Now we unite the both term under a common variable X, which would lead us to \n",
    "\n",
    "\\begin{align}\n",
    "‚à´_x p_{data} (x). log(D(x)) + p_x (x) log(1- D(x))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a45b0",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Maximizing at each point would get the whole equation maximized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb73eef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After solving, we get\n",
    "\n",
    "\\begin{align}\n",
    "D^*(x) =  \\frac{p_{data}(x)} {p_{data} (x) + p_g (x)} \n",
    "\\end{align}\n",
    "- this is the **Optimal Discriminator**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff73bee2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "now if $p_{data} = p_g $ i.e the data distribution has exactly half of real and fake samples., which means the discriminator hasto guess which image is real and which image is fake. \n",
    "- this takes its output D(x) = 1/2\n",
    "- if we subsitute this value then we get\n",
    "- $V(D^*, G) = -log 4$ which is also the maximum loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f76b7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we minimize the generator, for this we are going to substitute the above optimal discriminator in the original cost function. then we'll get, \n",
    "\\begin{align}\n",
    "ùîº_{x ‚àº p_{data} (x)} log [\\frac{p_{data}(x)} {p_{data} (x) + p_g (x)}] + ùîº_{P_{z} ‚àº z} log [\\frac{p_{g}(x)} {p_{data} (x) + p_g (x)}] \n",
    "\\end{align}\n",
    "According to **KL Divergence**\n",
    "\\begin{align}\n",
    "D_{KL} (P||Q)= ùîº {x \\sim p} [log \\frac{P(x)}{Q(x)}]\n",
    "\\end{align}\n",
    "on re-arranging the above terms, we can also write the above equation as,\n",
    "\\begin{align}\n",
    "D_{KL} (P||Q)= ùîº_{x \\sim p} [log \\frac{P(x)}{Q(x)/2}] - log(2)\n",
    "\\end{align}\n",
    "So, I am re-writing the above equation as,\n",
    "\\begin{align}\n",
    "min_{G}  V(D, G) = - log(4) + KL(\\frac{p_{data}}{p_{data}+p_g/2}) + KL(\\frac{p_{g}}{p_{data}+p_g/2})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4647e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "JSD is simply the distance between two probability distributions and KL divergence gives you how different the two given distributions are.\n",
    "Shakir md and co \n",
    "sebastian and co have paper discussing the different divergences relating to GANs as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188f7d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also know that Jenson Shanon divergence is given as, \n",
    "\\begin{align}\n",
    "JSD (P||Q) = \\frac{1}{2} D_{KL}(\\frac{P}{P+Q/2}) + \\frac{1}{2} D_{KL}(\\frac{Q}{P+Q/2})\n",
    "\\end{align}\n",
    "JSD is similar to KL but it is symmetric, Now Substituting we are going to get, \n",
    "\\begin{align}\n",
    "min_g  V(D,G) = - log (4) + 2. JSD(p_{data}||p_g)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028dbff",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "JSD becomes zero when the $p_{data} = p_g$ then you'll get the optimal discriminator function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7fca5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So, for an optimal discriminator, the generator is trying to minimize the below equation, \\begin{align}\n",
    "min_g  V(D,G) = - log (4) + 2. JSD(p_{data}||p_g)\n",
    "\\end{align}\n",
    "- minimum for any JSD is 0 if and only if the $p_{data} = p_g$\n",
    "- This shows that this cost function has 1 minimum and that is acheived when both the distributions are equal. \n",
    "- If both distibutions are equal, then we get $min_g V(D,G) = - log(4)$ which is our discriminator making coin fluke decisions when the real and fake data are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a66a97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "GANs are very sensitive to the hyper parameters\n",
    "- good parameters : https://www.youtube.com/watch?v=IUi0REAWj2c&t=4s\n",
    "- bad parameter : https://www.youtube.com/watch?v=J8m1NXLwSKw\n",
    "- more advanced parameters : wasserstein GANs(we'll talk about this later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465fa0c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of GANs\n",
    "### Deep Convolution GANs\n",
    "Architectural differences\n",
    "- Replaced any pooling layers with strided convolution(discrminator) and fractional-strided convolutions(generator)\n",
    "- Using batchnorm in both the generator and discriminator\n",
    "- Removed fully connected hidden layers for deeper archtectures\n",
    "- Use ReLU activation in generator for all layer except for output, which uses tanh\n",
    "- Use leakyrelu activation function in the discriminator for all layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a48811",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"dcgan.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd66fad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc110f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"dc1.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9149d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca60e2d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"dcf.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ff83a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"dcgif.gif\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4de43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional GANs\n",
    "GANs where you specify a condition on the generated images.\n",
    "\n",
    "<p align=\"center\">\n",
    "        <img src=\"ccgan.png\", >\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b04de5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# train generator\n",
    "        # pick random noise samples (z) from a normal distribution\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        \n",
    "        # pick random labels for conditioning\n",
    "        sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "        # use trained discriminator to improve generator\n",
    "        gen_loss = gan_model.train_on_batch([noise, sampled_labels], real_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc7664",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "        <img src=\"model.png\", >\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e1b12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "        <img src=\"cgan.png\", >\n",
    "    </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab56ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wasserstein GAN\n",
    "- training the critic using a mix of fake and real samples\n",
    "- calculate discriminator loss\n",
    "- train the critic 5 times per one training cycle of the generator\n",
    "- use wasserstein_loss for both generator and discriminator\n",
    "- fix the discriminator and generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a82ea",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This model is proposed to deal with the instability of the minmax game and the unintuitiveness of the generator loss. This problem is because we train the generator and discriminator simultanously and the generator's preformance is mainly dependent on the discriminator's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9beaf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Implementation details of W-GANs\n",
    "- the discriminator is termed as the critic, which generates and outputs a score \n",
    "of realness or fakeness. \n",
    "- the final layer in the critic/discriminator is a linear layer (instead of \n",
    "sigmoid).\n",
    "-  -1 denotes real labels, while 1 denotes fake labels. These are expressed as \n",
    "positive and negative critics in the literature. We otherwise use 1 and 0 for \n",
    "real and fake labels, respectively\n",
    "- We replace classification loss (binary cross-entropy) with Wasserstein loss.\n",
    "- The critic model is allowed to train for a greater number of cycles compared \n",
    "to the generator model. This is done because in the case of W-GANs, a stable \n",
    "critic better guides the generator; the gradients are much smoother. The \n",
    "authors trained the critic model five times per generator cycle.\n",
    "-  RMSProp is the recommended optimizer to allow stable training. This is in \n",
    "contrast to the usage of Adam as an optimizer for the typical case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53f3b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    " \"\"\"\n",
    " Custom loss function for W-GAN\n",
    " Parameters:\n",
    " y_true: type:np.array. Ground truth\n",
    " y_pred: type:np.array. Predicted score\n",
    " \"\"\"\n",
    " return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f4e5a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"wgan.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214e1a2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "WGAN-GP: https://www.youtube.com/watch?v=unXILX2wp1A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9de59f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Progressive GAN\n",
    "This is a method to increase the quality and the stability of the images produced by the gans. This was first presented in the paper **GANs for Improved Quality, Stability, and Variation**\n",
    "<p align=\"center\">\n",
    "        <img src=\"pgan.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4077c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"summary.png\", >\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9a802",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "        <img src=\"oppgan.png\", >\n",
    "    </p>\n",
    "    \n",
    "visit: https://github.com/PacktPublishing/Hands-On-Generative-AI-with-Python-and-TensorFlow-2/blob/master/Chapter_6/pro_gan_tfhub.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5cd7d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vector Arthematic\n",
    "Queen = King - Man + Women \n",
    "<p align=\"center\">\n",
    "        <img src=\"vectorarthematic.png\", >\n",
    "    </p>\n",
    "    \n",
    "first presented at **Radford et. al**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac7a09e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other GAN Architectures\n",
    "- LapGAN\n",
    "- Reccurrent Adversarial Network\n",
    "- Categorical GAN\n",
    "- InfoGAN\n",
    "- BiGAN\n",
    "- CycleGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37c5da",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Laplacian GAN(a chain of cgans) to generate progressive larger images\n",
    "- Categorical GAN is used for clustering and k mean\n",
    "- InfoGAN gives the information in the images it generates. The hidden space is divided into the information that you need and the noise you dont(encoders are involved)\n",
    "- Bi direction trains the encoders in two directions\n",
    "- cycle gans are already discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1876400",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Challenges \n",
    "- Non Convergence: since there are two players trying to minimize their own functions, we might never achieve equilibrium but we will come to a general region\n",
    "- Mode Collapse: $min_g max_d V(G,D)    != max_d min_g V(G,D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49563004",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### References\n",
    "- Ian Goodfellow' s work, NIPS workshops, and interviews.\n",
    "- Hands on Generative AI with python and Tensorflow book\n",
    "- Stanford lecture sessions\n",
    "- CMU lecture session\n",
    "#### Useful Resources\n",
    "- https://deepgenerativemodels.github.io/\n",
    "- https://sites.google.com/view/berkeley-cs294-158-sp19/home\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
